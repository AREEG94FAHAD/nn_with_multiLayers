{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32cfb9c1",
   "metadata": {},
   "source": [
    "# Multiple-layer neural networkÂ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78f9c60",
   "metadata": {},
   "source": [
    "A neural network system with multiple hidden layers for binary classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4494eb17",
   "metadata": {},
   "source": [
    "1. Prepare all helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6830869",
   "metadata": {},
   "source": [
    "a. Sigmoid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68427ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "    \"\"\"\n",
    "    Implements the sigmoid activation in numpy\n",
    "    \n",
    "    Arguments:\n",
    "    Z -- numpy array of any shape\n",
    "    \n",
    "    Returns:\n",
    "    A -- output of sigmoid(z), same shape as Z\n",
    "    cache -- returns Z as well, useful during backpropagation\n",
    "    \"\"\"\n",
    "    \n",
    "    A = 1/(1+np.exp(-Z))\n",
    "    cache = Z\n",
    "    \n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64616935",
   "metadata": {},
   "source": [
    "b. Relu (Rectified Linear Unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4700238b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(Z):\n",
    "    \"\"\"\n",
    "    Implement the RELU function.\n",
    "\n",
    "    Arguments:\n",
    "    Z -- Output of the linear layer, of any shape\n",
    "\n",
    "    Returns:\n",
    "    A -- Post-activation parameter, of the same shape as Z\n",
    "    cache -- a python dictionary containing \"A\" ; stored for computing the backward pass efficiently\n",
    "    \"\"\"\n",
    "    \n",
    "    A = np.maximum(0,Z)\n",
    "    \n",
    "    cache = Z \n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b6cd0b",
   "metadata": {},
   "source": [
    "c. Sigmoid back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc0deea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_backward(dA, cache):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation for a single SIGMOID unit.\n",
    "\n",
    "    Arguments:\n",
    "    dA -- post-activation gradient, of any shape\n",
    "    cache -- 'Z' where we store for computing backward propagation efficiently\n",
    "\n",
    "    Returns:\n",
    "    dZ -- Gradient of the cost with respect to Z\n",
    "    \"\"\"\n",
    "\n",
    "    Z = cache\n",
    "\n",
    "    s = 1/(1+np.exp(-Z))\n",
    "    dZ = dA * s * (1-s)\n",
    "\n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504a63d9",
   "metadata": {},
   "source": [
    "d. Relu back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "007e08f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_backward(dA, cache):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation for a single RELU unit.\n",
    "\n",
    "    Arguments:\n",
    "    dA -- post-activation gradient, of any shape\n",
    "    cache -- 'Z' where we store for computing backward propagation efficiently\n",
    "\n",
    "    Returns:\n",
    "    dZ -- Gradient of the cost with respect to Z\n",
    "    \"\"\"\n",
    "    \n",
    "    Z = cache\n",
    "    dZ = np.array(dA, copy=True) # just converting dz to a correct object.\n",
    "    \n",
    "    # When z <= 0, you should set dz to 0 as well. \n",
    "    dZ[Z <= 0] = 0\n",
    "    \n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d40f10c",
   "metadata": {},
   "source": [
    "2. Initialize required parameters (weights, bais)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "979d5a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters_deep(layer_dims):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    layer_dims -- python array (list) containing the dimensions of each layer in our network\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", ..., \"WL\", \"bL\":\n",
    "                    Wl -- weight matrix of shape (layer_dims[l], layer_dims[l-1])\n",
    "                    bl -- bias vector of shape (layer_dims[l], 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(1)\n",
    "    parameters = {}\n",
    "    L = len(layer_dims)            # number of layers in the network\n",
    "\n",
    "    for l in range(1, L):\n",
    "        parameters['W' + str(l)] = np.random.randn(layer_dims[l], layer_dims[l-1]) / np.sqrt(layer_dims[l-1]) #*0.01\n",
    "        parameters['b' + str(l)] = np.zeros((layer_dims[l], 1))\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c76cf5",
   "metadata": {},
   "source": [
    "3. Forward propagation\n",
    "\n",
    "In this section, the forward propagation functions will be initialized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93208ef",
   "metadata": {},
   "source": [
    "a. Linear Forward\n",
    "$Z^l = W^lA^{l-1}+b^l$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a47448c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forward(A, W, b):\n",
    "    \"\"\"\n",
    "    Implement the linear part of a layer's forward propagation.\n",
    "\n",
    "    Arguments:\n",
    "    A -- activations from previous layer (or input data): (size of previous layer, number of examples)\n",
    "    W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)\n",
    "    b -- bias vector, numpy array of shape (size of the current layer, 1)\n",
    "\n",
    "    Returns:\n",
    "    Z -- the input of the activation function, also called pre-activation parameter \n",
    "    cache -- a python dictionary containing \"A\", \"W\" and \"b\" ; stored for computing the backward pass efficiently\n",
    "    \"\"\"\n",
    "    \n",
    "    Z = W.dot(A) + b\n",
    "\n",
    "    cache = (A, W, b)\n",
    "    \n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0626f8a6",
   "metadata": {},
   "source": [
    "b. Linear -> activation\n",
    "\n",
    "$Z^l = W^lA^{[l-1]} + b \\rightarrow A^l = \\sigma(Z^l) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f5d77c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_forward(A_prev, W, b, activation):\n",
    "    \"\"\"\n",
    "    Implement the forward propagation for the LINEAR->ACTIVATION layer\n",
    "\n",
    "    Arguments:\n",
    "    A_prev -- activations from previous layer (or input data): (size of previous layer, number of examples)\n",
    "    W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)\n",
    "    b -- bias vector, numpy array of shape (size of the current layer, 1)\n",
    "    activation -- the activation to be used in this layer, stored as a text string: \"sigmoid\" or \"relu\"\n",
    "\n",
    "    Returns:\n",
    "    A -- the output of the activation function, also called the post-activation value \n",
    "    cache -- a python dictionary containing \"linear_cache\" and \"activation_cache\";\n",
    "             stored for computing the backward pass efficiently\n",
    "    \"\"\"\n",
    "    \n",
    "    if activation == \"sigmoid\":\n",
    "        # Inputs: \"A_prev, W, b\". Outputs: \"A, activation_cache\".\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = sigmoid(Z)\n",
    "    \n",
    "    elif activation == \"relu\":\n",
    "        # Inputs: \"A_prev, W, b\". Outputs: \"A, activation_cache\".\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = relu(Z)\n",
    "        \n",
    "    cache = (linear_cache, activation_cache)\n",
    "\n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddc13e1",
   "metadata": {},
   "source": [
    "c. forward propagation for all layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "522c3c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_forward(X, parameters):\n",
    "    \"\"\"\n",
    "    Implement forward propagation for the [LINEAR->RELU]*(L-1)->LINEAR->SIGMOID computation\n",
    "    \n",
    "    Arguments:\n",
    "    X -- data, numpy array of shape (input size, number of examples)\n",
    "    parameters -- output of initialize_parameters_deep()\n",
    "    \n",
    "    Returns:\n",
    "    AL -- last post-activation value\n",
    "    caches -- list of caches containing:\n",
    "                every cache of linear_relu_forward() (there are L-1 of them, indexed from 0 to L-2)\n",
    "                the cache of linear_sigmoid_forward() (there is one, indexed L-1)\n",
    "    \"\"\"\n",
    "\n",
    "    caches = []\n",
    "    A = X\n",
    "    L = len(parameters) // 2                  # number of layers in the neural network\n",
    "    \n",
    "    # Implement [LINEAR -> RELU]*(L-1). Add \"cache\" to the \"caches\" list.\n",
    "    for l in range(1, L):\n",
    "        A_prev = A \n",
    "        A, cache = linear_activation_forward(A_prev, parameters['W' + str(l)], parameters['b' + str(l)], activation = \"relu\")\n",
    "        caches.append(cache)\n",
    "    \n",
    "    # Implement LINEAR -> SIGMOID. Add \"cache\" to the \"caches\" list.\n",
    "    AL, cache = linear_activation_forward(A, parameters['W' + str(L)], parameters['b' + str(L)], activation = \"sigmoid\")\n",
    "    caches.append(cache)\n",
    "\n",
    "            \n",
    "    return AL, caches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e71cde",
   "metadata": {},
   "source": [
    "4. Compute the cross-entropy cost \n",
    "\n",
    "$J$, using the following formula: $$-\\frac{1}{m} \\sum\\limits_{i = 1}^{m} (y^{(i)}\\log\\left(a^{[L] (i)}\\right) + (1-y^{(i)})\\log\\left(1- a^{[L](i)}\\right))$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ce2f908",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(AL, Y):\n",
    "    \n",
    "    \"\"\"\n",
    "    Argument:\n",
    "\n",
    "    AL -- probability vector corresponding to your label predictions, shape (1, number of examples)\n",
    "    Y -- true \"label\" vector (for example: containing 0 if non-cat, 1 if cat), shape (1, number of examples)\n",
    "    \n",
    "    Return:\n",
    "    \n",
    "    cost -- cross-entropy cost\n",
    "\n",
    "    \"\"\"\n",
    "    m = Y.shape[1]\n",
    "    \n",
    "    cost = (1./m) * (-np.dot(Y,np.log(AL).T) - np.dot(1-Y, np.log(1-AL).T))\n",
    "    \n",
    "    cost = np.squeeze(cost)      # To make sure your cost's shape is what we expect (e.g. this turns [[17]] into 17).\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de1d303",
   "metadata": {},
   "source": [
    "7. Linear backward\n",
    "\n",
    "a. Backward Linear \n",
    " * Forward linear =   $Z = WA+ b$\n",
    " \n",
    " * Backward Linear = $ \\frac{\\partial J}{ \\partial W^{[l]}}, \\frac{\\partial J}{ \\partial A^{[l-1]}}, \\frac{\\partial J}{ \\partial b{[l]}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0543f11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_backward(dZ, cache):\n",
    "    \n",
    "    #important three equation\n",
    "    # dJ/dW2 = dJ/dZ2 . dZ/dW2\n",
    "    # dJ/db2 = dJ/dZ2 . dZ/db1\n",
    "    # dJ/dA1 = dJ/dZ2 . dZ/dW2\n",
    "    \n",
    "    \"\"\"\n",
    "    Argument:\n",
    "    dZ: derviative of Z of current layer\n",
    "    cache: A Python tuple contains the current layer's A_prev, weights, and b.Â \n",
    "    \n",
    "    return: \n",
    "    derivative of current layer weights and bais, and previous layer dAÂ \n",
    "\n",
    "    \"\"\"\n",
    "    A_prev, W, b = cache\n",
    "\n",
    "    m = A_prev.shape[1]  # number of example\n",
    "\n",
    "    dW = 1./m * np.dot(dZ, A_prev.T)\n",
    "    db = 1./m * np.sum(dZ, axis=1, keepdims=True)\n",
    "    dA_prev = np.dot(W.T, dZ)\n",
    "\n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132799dd",
   "metadata": {},
   "source": [
    "b. Linear_activation_back\n",
    "\n",
    "compute $\\frac{\\partial J}{\\partial Z}$ to use for compute linear backward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01856296",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_backward(dA, cache, activation):\n",
    "\n",
    "    # dJ/dZ = dJ/dA . dA/dZ --- then used dZ to compute dA previous, dw current, db current.\n",
    "    \"\"\"\n",
    "    dA -- post-activation gradient for current layer l \n",
    "    cache -- tuple of values (linear_cache, activation_cache) we store for computing backward propagation efficiently\n",
    "    activation -- the activation to be used in this layer, stored as a text string: \"sigmoid\" or \"relu\"\n",
    "\n",
    "    Returns:\n",
    "    dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n",
    "    dW -- Gradient of the cost with respect to W (current layer l), same shape as W\n",
    "    db -- Gradient of the cost with respect to b (current layer l), same shape as b\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    linear_cache, activation_cache = cache\n",
    "\n",
    "    if activation == \"relu\":\n",
    "        dZ = relu_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "\n",
    "    if activation == 'sigmoid':\n",
    "\n",
    "        dZ = sigmoid_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "\n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c2ddb7",
   "metadata": {},
   "source": [
    "c. Backward propagation for all layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a80e994",
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_backward(AL, Y, caches):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation for the [LINEAR->RELU] * (L-1) -> LINEAR -> SIGMOID group\n",
    "    \n",
    "    Arguments:\n",
    "    AL -- probability vector, output of the forward propagation (L_model_forward())\n",
    "    Y -- true \"label\" vector (containing 0 if non-cat, 1 if cat)\n",
    "    caches -- list of caches containing:\n",
    "                every cache of linear_activation_forward() with \"relu\" (it's caches[l], for l in range(L-1) i.e l = 0...L-2)\n",
    "                the cache of linear_activation_forward() with \"sigmoid\" (it's caches[L-1])\n",
    "    \n",
    "    Returns:\n",
    "    grads -- A dictionary with the gradients\n",
    "             grads[\"dA\" + str(l)] = ... \n",
    "             grads[\"dW\" + str(l)] = ...\n",
    "             grads[\"db\" + str(l)] = ... \n",
    "    \"\"\"\n",
    "    grads = {}\n",
    "    L = len(caches) # the number of layers\n",
    "    m = AL.shape[1]\n",
    "    Y = Y.reshape(AL.shape) # after this line, Y is the same shape as AL\n",
    "    \n",
    "    # Initializing the backpropagation\n",
    "    ### START CODE HERE ### (1 line of code)\n",
    "    dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Lth layer (SIGMOID -> LINEAR) gradients. Inputs: \"AL, Y, caches\". Outputs: \"grads[\"dAL\"], grads[\"dWL\"], grads[\"dbL\"]\n",
    "    ### START CODE HERE ### (approx. 2 lines)\n",
    "    current_cache = caches[L-1]\n",
    "    grads[\"dA\" + str(L-1)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = linear_activation_backward(dAL, current_cache, activation = \"sigmoid\")\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    for l in reversed(range(L-1)):\n",
    "        # lth layer: (RELU -> LINEAR) gradients.\n",
    "        # Inputs: \"grads[\"dA\" + str(l + 2)], caches\". Outputs: \"grads[\"dA\" + str(l + 1)] , grads[\"dW\" + str(l + 1)] , grads[\"db\" + str(l + 1)] \n",
    "        ### START CODE HERE ### (approx. 5 lines)\n",
    "        current_cache = caches[l]\n",
    "        dA_prev_temp, dW_temp, db_temp = linear_activation_backward(grads[\"dA\" + str(l + 1)],  current_cache, activation = \"relu\")\n",
    "        grads[\"dA\" + str(l)] = dA_prev_temp\n",
    "        grads[\"dW\" + str(l + 1)] = dW_temp\n",
    "        grads[\"db\" + str(l + 1)] = db_temp\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcc499d",
   "metadata": {},
   "source": [
    "8. update parameters (weights and bais)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05aff4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parmeters, grads, learning_rate):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "    parameters: a python dictionary containing weights and bais of all layers\n",
    "    grads: a Python dictionary containing derivatives of weights and bases of all layers\n",
    "\n",
    "    Return:\n",
    "    parameters -- python dictionary containing your updated parameters \n",
    "                  parameters[\"W\" + str(l)] = ... \n",
    "                  parameters[\"b\" + str(l)] = ...\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    L = len(parmeters)//2\n",
    "    \n",
    "    for l in range(L):\n",
    "        parmeters[\"W\"+str(l+1)] = parmeters[\"W\"+str(l+1)] - learning_rate * grads[\"dW\"+str(l+1)] \n",
    "        parmeters[\"b\"+str(l+1)] = parmeters[\"b\"+str(l+1)] - learning_rate * grads[\"db\"+str(l+1)]\n",
    "    \n",
    "    return parmeters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a36f3c",
   "metadata": {},
   "source": [
    "11. calculate the acurracyÂ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f431f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, y, parameters):\n",
    "    \"\"\"\n",
    "    This function is used to predict the results of a  L-layer neural network.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- data set of examples you would like to label\n",
    "    parameters -- parameters of the trained model\n",
    "    \n",
    "    Returns:\n",
    "    p -- predictions for the given dataset X\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    n = len(parameters) // 2 # number of layers in the neural network\n",
    "    p = np.zeros((1,m))\n",
    "    \n",
    "    # Forward propagation\n",
    "    probas, caches = L_model_forward(X, parameters)\n",
    "\n",
    "    \n",
    "    # convert probas to 0/1 predictions\n",
    "    for i in range(0, probas.shape[1]):\n",
    "        if probas[0,i] > 0.5:\n",
    "            p[0,i] = 1\n",
    "        else:\n",
    "            p[0,i] = 0\n",
    "    \n",
    "    #print results\n",
    "    #print (\"predictions: \" + str(p))\n",
    "    #print (\"true labels: \" + str(y))\n",
    "    print(\"Accuracy: \"  + str(np.sum((p == y)/m)))\n",
    "        \n",
    "    return p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41991c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_dims = [12288, 20, 7, 5, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35b3ea87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_layer_model(X, Y, layers_dims, learning_rate = 0.0075, num_iterations = 3000, print_cost=False):\n",
    "    \"\"\"\n",
    "    Implements a L-layer neural network: [LINEAR->RELU]*(L-1)->LINEAR->SIGMOID.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- data, numpy array of shape (num_px * num_px * 3, number of examples)\n",
    "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)\n",
    "    layers_dims -- list containing the input size and each layer size, of length (number of layers + 1).\n",
    "    learning_rate -- learning rate of the gradient descent update rule\n",
    "    num_iterations -- number of iterations of the optimization loop\n",
    "    print_cost -- if True, it prints the cost every 100 steps\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "\n",
    "    np.random.seed(1)\n",
    "    costs = []                         # keep track of cost\n",
    "    \n",
    "    # Parameters initialization.\n",
    "    #(â 1 line of code)\n",
    "    # parameters = ...\n",
    "    # YOUR CODE STARTS HERE\n",
    "    parameters = initialize_parameters_deep(layers_dims)\n",
    "    \n",
    "    # YOUR CODE ENDS HERE\n",
    "    \n",
    "    # Loop (gradient descent)\n",
    "    for i in range(0, num_iterations):\n",
    "\n",
    "        # Forward propagation: [LINEAR -> RELU]*(L-1) -> LINEAR -> SIGMOID.\n",
    "        #(â 1 line of code)\n",
    "        # AL, caches = ...\n",
    "        # YOUR CODE STARTS HERE\n",
    "        AL, caches = L_model_forward(X, parameters)\n",
    "        \n",
    "        # YOUR CODE ENDS HERE\n",
    "        \n",
    "        # Compute cost.\n",
    "        #(â 1 line of code)\n",
    "        # cost = ...\n",
    "        # YOUR CODE STARTS HERE\n",
    "        cost = compute_cost(AL, Y)\n",
    "        \n",
    "        # YOUR CODE ENDS HERE\n",
    "    \n",
    "        # Backward propagation.\n",
    "        #(â 1 line of code)\n",
    "        # grads = ...    \n",
    "        # YOUR CODE STARTS HERE\n",
    "        grads = L_model_backward(AL, Y, caches)\n",
    "        \n",
    "        # YOUR CODE ENDS HERE\n",
    " \n",
    "        # Update parameters.\n",
    "        #(â 1 line of code)\n",
    "        # parameters = ...\n",
    "        # YOUR CODE STARTS HERE\n",
    "        parameters = update_parameters(parameters, grads, learning_rate)\n",
    "        \n",
    "        # YOUR CODE ENDS HERE\n",
    "                \n",
    "        # Print the cost every 100 iterations\n",
    "        if print_cost and i % 100 == 0 or i == num_iterations - 1:\n",
    "            print(\"Cost after iteration {}: {}\".format(i, np.squeeze(cost)))\n",
    "        if i % 100 == 0 or i == num_iterations:\n",
    "            costs.append(cost)\n",
    "    \n",
    "    return parameters, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "175e475a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "    \n",
    "def load_dataset():\n",
    "    \n",
    "    # load the training data from train_catvnoncat.h5 file\n",
    "    \n",
    "    train_dataset = h5py.File('datasets/train_catvnoncat.h5', \"r\")\n",
    "    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n",
    "    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n",
    "\n",
    "    # load the test data from test_catvnoncat.h5 file\n",
    "    \n",
    "    test_dataset = h5py.File('datasets/test_catvnoncat.h5', \"r\")\n",
    "    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n",
    "    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n",
    "\n",
    "    classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\n",
    "    \n",
    "    # train_set_y_orig.shape = (209,)\n",
    "    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
    "    # train_set_y_orig.shape = (1,209)\n",
    "    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
    "    \n",
    "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a56a549",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_x_orig, train_set_y, test_set_x_orig, test_set_y, classes = load_dataset()\n",
    "\n",
    "num_of_sample, width_of_image, heigh_of_image, channel = train_set_x_orig.shape\n",
    "\n",
    "# Convert (209, 64, 64, 3) to (209, 12288)\n",
    "train_set_x_flatten = train_set_x_orig.reshape(num_of_sample, width_of_image*heigh_of_image*channel)\n",
    "\n",
    "# Convert (209, 12288) to (12288, 209) and normalization\n",
    "train_set_x = train_set_x_flatten.T / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f2714fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.7717493284237686\n",
      "Cost after iteration 100: 0.6720534400822914\n",
      "Cost after iteration 200: 0.6482632048575212\n",
      "Cost after iteration 300: 0.6115068816101354\n",
      "Cost after iteration 400: 0.5670473268366111\n",
      "Cost after iteration 500: 0.54013766345478\n",
      "Cost after iteration 600: 0.5279299569455267\n",
      "Cost after iteration 700: 0.4654773771766851\n",
      "Cost after iteration 800: 0.3691258524959279\n",
      "Cost after iteration 900: 0.39174697434805344\n",
      "Cost after iteration 1000: 0.3151869888600617\n",
      "Cost after iteration 1100: 0.2726998441789385\n",
      "Cost after iteration 1200: 0.23741853400268137\n",
      "Cost after iteration 1300: 0.19960120532208647\n",
      "Cost after iteration 1400: 0.18926300388463305\n",
      "Cost after iteration 1500: 0.1611885466582775\n",
      "Cost after iteration 1600: 0.14821389662363316\n",
      "Cost after iteration 1700: 0.13777487812972944\n",
      "Cost after iteration 1800: 0.1297401754919012\n",
      "Cost after iteration 1900: 0.12122535068005211\n",
      "Cost after iteration 2000: 0.1138206066863371\n",
      "Cost after iteration 2100: 0.10783928526254133\n",
      "Cost after iteration 2200: 0.10285466069352679\n",
      "Cost after iteration 2300: 0.10089745445261787\n",
      "Cost after iteration 2400: 0.09287821526472397\n",
      "Cost after iteration 2499: 0.088439943441702\n"
     ]
    }
   ],
   "source": [
    "parameters, costs = L_layer_model(train_set_x, train_set_y, layers_dims, num_iterations = 2500, print_cost = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7060c71f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9856459330143539\n"
     ]
    }
   ],
   "source": [
    "training_examples_accuracy = predict(train_set_x, train_set_y, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e320fbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_sample, width_of_image, heigh_of_image, channel = test_set_x_orig.shape\n",
    "\n",
    "# Convert (50, 64, 64, 3) to (50, 12288)\n",
    "test_set_x_orig_flatten = test_set_x_orig.reshape(num_of_sample, width_of_image*heigh_of_image*channel)\n",
    "\n",
    "# Convert (50, 12288) to (12288, 50) and normalization \n",
    "test_set_x = test_set_x_orig_flatten.T / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6110f55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8\n"
     ]
    }
   ],
   "source": [
    "training_examples_accuracy = predict(test_set_x, test_set_y, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e3cc144d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "The image dose not contain a cat\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The system accepts only shapes in the form of (112288, for example).\n",
    "# As a result, the single example must be converted to (number of features , number of examples).Â \n",
    "\n",
    "import random\n",
    "index = random.randint(0, 208)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(train_set_x_orig[index])\n",
    "\n",
    "image = train_set_x[:, index].reshape(-1, 1)\n",
    "image_y = train_set_y[:, index].reshape(-1, 1)\n",
    "\n",
    "im = predict(image, image_y, parameters)\n",
    "\n",
    "if image_y[0][0] == 1:\n",
    "    if image_y[0][0] == int(im[0][0]):\n",
    "        print(\"The image contains a cat\")\n",
    "    else:\n",
    "        print(\"The image dose not contain a cat\")\n",
    "        \n",
    "else: \n",
    "    if image_y[0][0] == int(im[0][0]):\n",
    "        print(\"The image dose not contain a cat\")\n",
    "    else:\n",
    "        print(\"The image dose  contains a cat\")\n",
    "    \n",
    "# else:\n",
    "#     if image_y[0][0] == int(im[0][0]):\n",
    "#         print(\"The image dose not contain a cat\")\n",
    "#     else:\n",
    "#         print(\"The image dose not contain a cat\")\n",
    "        \n",
    "        \n",
    "        \n",
    "# print(image_y[0][0])\n",
    "# print(int(im[0][0]))\n",
    "\n",
    "    \n",
    "\n",
    "# print(train_set_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a4d56a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5251ccbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
